{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Least Squares and Marching Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open(\"data/input.pkl\", \"rb\") as f: points, normals = pickle.load(f);\n",
    "points, normals = torch.from_numpy(points), torch.from_numpy(normals);\n",
    "\n",
    "with open(\"data/gt.pkl\", \"rb\") as f: gt_values, gt_contour = pickle.load(f);\n",
    "gt_values, gt_contour = torch.from_numpy(gt_values), torch.from_numpy(gt_contour);\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.scatter(points[:, 0], points[:, 1], s = 6.0, color = \"r\");\n",
    "\n",
    "for i in range(len(normals)):\n",
    "    p = points[i]\n",
    "    n = normals[i] / 40.0  # Scale normal for better visualization\n",
    "    plt.arrow(p[0], p[1], n[0], n[1], color='b', head_width=0.01, head_length=0.01)\n",
    "\n",
    "plt.title(\"Points and Normals\")\n",
    "xlim, ylim = [0.0, 3.2], [0.0, 1.8];\n",
    "plt.xlim(xlim);\n",
    "plt.ylim(ylim);\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 1: Approximation of Implicit Function from a Point Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we use **Implicit Moving Least Squares (IMLS)** to approximate an implicit function $f(\\mathbf{x})$ given a set of points $\\{\\mathbf{p}_i\\}$ and their associated normals $\\{\\mathbf{n}_i\\}$. The IMLS method computes $f(\\mathbf{x})$ by a **weighted average** of local contributions from each neighbor point:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) \n",
    "\\;=\\;\n",
    "\\frac{\\displaystyle \\sum_{i} w_i \\,\\bigl(\\mathbf{x} - \\mathbf{p}_i\\bigr)^{T} \\,\\mathbf{n}_i}\n",
    "     {\\displaystyle \\sum_{i} w_i}.\n",
    "$$\n",
    "\n",
    "\n",
    "### Weight Function\n",
    "\n",
    "To capture local influence, each point $\\mathbf{p}_i$ contributes a weight $\\mathbf{w}_i$. You should use a Gaussian‐like kernel:\n",
    "\n",
    "$$\n",
    "w_i \n",
    "\\;=\\; \n",
    "\\frac{1}{k_i} \\exp\\!\\Bigl(\\!-\\tfrac{\\|\\mathbf{x} - \\mathbf{p}_i\\|^2}{\\epsilon^2}\\Bigr),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\epsilon$ is a *radius* parameter controlling the falloff of influence (sometimes referred to as the “ball radius”). We use 0.01.\n",
    "- $k_i$ is the number of neighbor points within $\\epsilon$ of $\\mathbf{p}_i$.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-2;\n",
    "dist = torch.cdist(points, points);\n",
    "k = torch.sum(dist < eps, dim = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_value(x):\n",
    "    '''\n",
    "        Input\n",
    "            x: torch.tensor [#query points, 2(dimension)]\n",
    "        Output\n",
    "            f_x: torch.tensor [#query points,]\n",
    "        \n",
    "        Implement the approximation of the Implicit Function\n",
    "        using Implicit Moving Least Squares method.\n",
    "    '''\n",
    "\n",
    "    # ======================= TODO ===========================\n",
    "    # DO NOT MODIFY OUTSIDE\n",
    "\n",
    "    f_x = None;\n",
    "    \n",
    "    # DO NOT MODIFY OUTSIDE\n",
    "    # ======================= TODO ===========================\n",
    "    return f_x;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Implicit Function ($Look\\ at\\ the\\ title\\ of\\ the\\ plot\\ for\\ Top\\ 90\\%\\ Error$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(*xlim, 160);\n",
    "y = np.linspace(*ylim, 90);\n",
    "X, Y = np.meshgrid(x, y);\n",
    "coord = torch.from_numpy(np.stack((X.reshape(-1), Y.reshape(-1)), axis = 1));\n",
    "Z = get_f_value(coord).reshape(X.shape);\n",
    "error = torch.sort(torch.abs(gt_values - Z).reshape(-1))[0];\n",
    "\n",
    "plt.figure(figsize=(16, 9));\n",
    "plt.imshow(torch.clamp(Z * 10.0, -0.5, 0.5), extent=[*xlim, *ylim], origin='lower', cmap='coolwarm');\n",
    "plt.title(\"Visualization of Implicit Function restored by Moving Least Squares, Top 90% Error: {:.4f}\".format(error[int(error.shape[0] * 0.9)]));\n",
    "plt.colorbar()\n",
    "plt.xlim(xlim);\n",
    "plt.ylim(ylim);\n",
    "plt.gca().invert_yaxis();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Task 2: Marching Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marching Squares** is a **2D** algorithm to extract a contour (or iso‐curve) from a scalar field $F(\\mathbf{x})$. It is the 2D analogue of the well‐known **Marching Cubes** algorithm in 3D.\n",
    "\n",
    "1. **Grid the Domain**  \n",
    "   - You overlay a uniform grid over the bounding box that contains your data.  \n",
    "   - At each grid cell corner \\((i, j)\\), you evaluate \\(F(i, j)\\).\n",
    "\n",
    "2. **Cell Classification**  \n",
    "   - For each cell (which has 4 corners), you check if each corner’s value is above or below the iso‐level (often \\(F = 0\\)).  \n",
    "   - This gives you a pattern of bits (e.g., 0 for below, 1 for above), which indicates which edges of the cell the contour will cross.\n",
    "\n",
    "3. **Edge Interpolation**  \n",
    "   - If two corners differ in sign, the contour must pass somewhere between them.  \n",
    "   - You compute the intersection point by linearly interpolating along the edge:\n",
    "\n",
    "     $$\n",
    "     \\mathbf{p} \\;=\\; \\mathbf{p}_1 \\;+\\; \\alpha\\,(\\mathbf{p}_2 - \\mathbf{p}_1),\n",
    "     \\quad \\text{where} \\quad\n",
    "     \\alpha \\;=\\; \\frac{\\,0 - F(\\mathbf{p}_1)\\,}{F(\\mathbf{p}_2) \\;-\\; F(\\mathbf{p}_1)}.\n",
    "     $$\n",
    "\n",
    "4. **Connecting Segments**  \n",
    "   - Based on which edges are intersected, you connect the intersection points within each cell to form small line segments.  \n",
    "   - These line segments across all cells piece together to form continuous contours.  \n",
    "   - Special **ambiguous cases** (where a cell’s corners give four intersections) require disambiguation rules so that the lines connect consistently.\n",
    "\n",
    "5. **Outcome**  \n",
    "   - The final result is a collection of line segments or polylines forming the approximate curve $F(\\mathbf{x})= 0$.  \n",
    "   - Marching Squares is **straightforward**, **efficient**, and widely used in scientific visualization and image processing.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_offset = torch.tensor([\n",
    "    [0, 0], # location of point 0    of cell at (y, x): (y, x) + (0, 0)\n",
    "    [0, 1], # location of point 1    of cell at (y, x): (y, x) + (0, 1)\n",
    "    [1, 1], # location of point 2    of cell at (y, x): (y, x) + (1, 1)\n",
    "    [1, 0]  # location of point 3    of cell at (y, x): (y, x) + (1, 0)\n",
    "], dtype = torch.int64);\n",
    "\n",
    "edge_to_points = torch.tensor([\n",
    "    [0, 1], # edge 0:  point 0 and point 1\n",
    "    [1, 2], # edge 1:  point 1 and point 2\n",
    "    [2, 3], # edge 2:  point 2 and point 3\n",
    "    [3, 0]  # edge 3:  point 3 and point 0\n",
    "], dtype = torch.int64);\n",
    "\n",
    "\n",
    "\n",
    "# ======================= TODO ===========================\n",
    "# DO NOT MODIFY OUTSIDE\n",
    "'''\n",
    "    Fill out the table \"case_to_edges\".\n",
    "    \n",
    "    case 0011 (binary) means that grid points 2 and 3 (see \"points_to_offset\" for indexing)\n",
    "    out of 4 grid points of a grid cell have larger values than the level(=0.0).\n",
    "    \n",
    "    If the \"case_to_edges\" element for a case is given by [[0, 1], [-1, -1]],\n",
    "    then for the first element [0, 1], it will find the 0-level points\n",
    "    along the edge 0 and edge 1 (see \"edge_to_points\" for indexing),\n",
    "    and draw a line between the points found.\n",
    "    Also, for the second element [-1, -1], it will skip to draw a line segment in this case.\n",
    "\n",
    "    Note that you don't have to address the ambiguous cases in this assignment.\n",
    "'''\n",
    "\n",
    "case_to_edges = torch.tensor([\n",
    "    [[-1, -1], [-1, -1]], # case 0   0000\n",
    "    [[-1, -1], [-1, -1]], # case 1   1000\n",
    "    [[-1, -1], [-1, -1]], # case 2   0100\n",
    "    [[-1, -1], [-1, -1]], # case 3   1100\n",
    "    [[-1, -1], [-1, -1]], # case 4   0010\n",
    "    [[-1, -1], [-1, -1]], # case 5   1010\n",
    "    [[-1, -1], [-1, -1]], # case 6   0110\n",
    "    [[-1, -1], [-1, -1]], # case 7   1110\n",
    "    [[-1, -1], [-1, -1]], # case 8   0001\n",
    "    [[-1, -1], [-1, -1]], # case 9   1001\n",
    "    [[-1, -1], [-1, -1]], # case 10  0101\n",
    "    [[-1, -1], [-1, -1]], # case 11  1101\n",
    "    [[-1, -1], [-1, -1]], # case 12  0011\n",
    "    [[-1, -1], [-1, -1]], # case 13  1011\n",
    "    [[-1, -1], [-1, -1]], # case 14  0111\n",
    "    [[-1, -1], [-1, -1]]  # case 15  1111\n",
    "], dtype = torch.int64);\n",
    "\n",
    "# DO NOT MODIFY OUTSIDE\n",
    "# ======================= TODO ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marching_squares(data, level = 0.0):\n",
    "    Ny, Nx = data.shape\n",
    "    # sdf value for (y, x): data[y, x]\n",
    "    grid_index = torch.arange(Ny * Nx).reshape(Ny, Nx);\n",
    "    cell_index = grid_index[:-1, :-1]; # Ny-1 x Nx-1\n",
    "    cell_coord = torch.stack((cell_index // Nx, cell_index % Nx), dim = 2);\n",
    "\n",
    "    cell_cases = torch.zeros_like(cell_index); # Ny-1 x Nx-1\n",
    "    for case, offset in zip([1, 2, 4, 8], points_to_offset):\n",
    "        cell_case = (data[cell_coord[..., 0] + offset[0], cell_coord[..., 1] + offset[1]] > level).to(cell_index.dtype);\n",
    "        cell_cases += case * cell_case;\n",
    "\n",
    "    contour = [];\n",
    "    for edgei in range(2):\n",
    "        edges = case_to_edges[cell_cases, edgei]; # Ny-1 x Nx-1 x 2\n",
    "        exist = edges[..., 0] != -1; # Ny-1 x Nx-1\n",
    "        edges = edges[exist]; # B x 2\n",
    "        cell_crd = cell_coord[exist].view(-1, 1, 1, 2); # B x 1 x 1 x 2\n",
    "        coords_ = points_to_offset[edge_to_points[edges]] + cell_crd # B x 2 x 2 x 2\n",
    "        values_ = data[coords_[..., 0], coords_[..., 1]]; # B x 2 x 2\n",
    "\n",
    "        ts_ = (level - values_[..., 0]) / (values_[..., 1] - values_[..., 0]); # B x 2\n",
    "        ts_ = torch.clamp(ts_.unsqueeze(2), 0.0, 1.0); # B x 2 x 1\n",
    "        points_ = coords_[:, :, 0] + ts_ * (coords_[:, :, 1] - coords_[:, :, 0]); # B x 2 x 2\n",
    "        points_ = torch.flip(points_, [-1]);\n",
    "        scale = torch.tensor([[[(xlim[1] - xlim[0]) / Nx, (ylim[1] - ylim[0]) / Ny]]]);\n",
    "        start = torch.tensor([[[xlim[0], ylim[0]]]]);\n",
    "        contour.append(start + points_ * scale);\n",
    "    \n",
    "    contour = torch.cat(contour, dim = 0);\n",
    "    return contour;\n",
    "\n",
    "contours = marching_squares(Z);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the Contour ($Look\\ at\\ the\\ title\\ of\\ the\\ plot\\ for\\ the\\ Metrics$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_segment_distance(points, seg_start, seg_end):\n",
    "    seg_vec = seg_end - seg_start;  # [M, D]\n",
    "    seg_len_sq = torch.sum(seg_vec**2, dim=-1, keepdim=True);  # [M, 1]\n",
    "    \n",
    "    p_vec = points[:, None, :] - seg_start[None, :, :];  # [N, M, D]\n",
    "    proj = torch.sum(p_vec * seg_vec, dim=-1, keepdim=True) / seg_len_sq;  # [N, M, 1]\n",
    "    proj = torch.clamp(proj, 0, 1);  # Clamp to segment [0, 1]\n",
    "    \n",
    "    closest_points = seg_start[None, :, :] + proj * seg_vec[None, :, :];  # [N, M, D]\n",
    "    dists = torch.norm(points[:, None, :] - closest_points, dim=-1);  # [N, M]\n",
    "    return dists;\n",
    "\n",
    "def hausdorff_distance(set1, set2):\n",
    "    start1, end1 = set1[:, 0, :], set1[:, 1, :];  # [N, D]\n",
    "    start2, end2 = set2[:, 0, :], set2[:, 1, :];  # [M, D]\n",
    "\n",
    "    min_d1 = torch.min(torch.minimum(point_to_segment_distance(start1, start2, end2),\n",
    "                                     point_to_segment_distance(end1, start2, end2)),\n",
    "                       dim=1)[0];  # Min for each row [N]\n",
    "    min_d2 = torch.min(torch.minimum(point_to_segment_distance(start2, start1, end1),\n",
    "                                     point_to_segment_distance(end2, start1, end1)),\n",
    "                       dim=1)[0];  # Min for each row [M]\n",
    "\n",
    "    directed_H1 = torch.max(min_d1);  # A -> B\n",
    "    directed_H2 = torch.max(min_d2);  # B -> A\n",
    "    return torch.max(directed_H1, directed_H2).item();\n",
    "\n",
    "def degree2_ratio(contours):\n",
    "    contour_ = contours.clone(); contour_ = (contours * 10000000).to(torch.int32);\n",
    "    verts_unq = list(set([tuple(x.numpy().tolist()) for x in contour_.view(-1, 2)]));\n",
    "    verts_idx = {vert: i for i, vert in enumerate(verts_unq)};\n",
    "\n",
    "    V = len(verts_unq);\n",
    "    degree = torch.zeros((V,), dtype = torch.int32);\n",
    "    for vert0, vert1 in contour_:\n",
    "        idx0 = verts_idx[tuple(vert0.numpy().tolist())];\n",
    "        idx1 = verts_idx[tuple(vert1.numpy().tolist())];\n",
    "        degree[idx0] += 1; degree[idx1] += 1;\n",
    "    return torch.sum(degree == 2).item() / V;\n",
    "\n",
    "plt.figure(figsize=(16, 9));\n",
    "for (x1, y1), (x2, y2) in contours:\n",
    "    plt.plot([x1, x2], [y1, y2], 'b-', linewidth=2);\n",
    "plt.title(\"Visualization of Contour restored by Marching Squares, Hausdorff Distance: {:.4f}, Ratio of Degree 2: {:.4f}\".format(\n",
    "    hausdorff_distance(contours, gt_contour), degree2_ratio(contours)));\n",
    "plt.xlim(xlim);\n",
    "plt.ylim(ylim);\n",
    "plt.gca().invert_yaxis();\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
